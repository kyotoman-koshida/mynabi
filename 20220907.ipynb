{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import mojimoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらなる特徴量の抽出を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、現在ある「市区町村」ではターゲットを推測するにあたって弱い気がするので、カテゴリ変数である「所在地」特徴量を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一括で処理ができるように、訓練データとテストデータを結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_target, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合する前のdf_targetのサイズ： 31470\n",
      "結合する前のdf_testのサイズ： 31262\n",
      "len(df_target)+len(df_test)= 62732\n",
      "結合したdfのサイズ： 62732\n"
     ]
    }
   ],
   "source": [
    "print('結合する前のdf_targetのサイズ：',len(df_target))\n",
    "print('結合する前のdf_testのサイズ：',len(df_test))\n",
    "print('len(df_target)+len(df_test)=',len(df_target)+len(df_test))\n",
    "print('結合したdfのサイズ：',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          東京都北区滝野川３丁目\n",
       "1          東京都中央区月島３丁目\n",
       "2          東京都渋谷区笹塚２丁目\n",
       "3    東京都杉並区高円寺南２丁目23-2\n",
       "4       東京都葛飾区金町３丁目7-2\n",
       "Name: 所在地, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['所在地'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"東京都○○区△△n丁目\"のうちの、○○区△△nを抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリ化前の訓練データ：\n",
      "          所在地\n",
      "0       北区滝野川\n",
      "1       中央区月島\n",
      "2       渋谷区笹塚\n",
      "3     杉並区高円寺南\n",
      "4       葛飾区金町\n",
      "5      荒川区南千住\n",
      "6      練馬区東大泉\n",
      "7       目黒区鷹番\n",
      "8       文京区向丘\n",
      "9       板橋区板橋\n",
      "10     大田区西馬込\n",
      "11    江戸川区北小岩\n",
      "12      港区南青山\n",
      "13    杉並区阿佐谷南\n",
      "14       墨田区緑\n",
      "15     渋谷区幡ヶ谷\n",
      "16      板橋区桜川\n",
      "17    江戸川区西瑞江\n",
      "18    新宿区四谷三栄\n",
      "19  中央区日本橋箱崎町\n",
      "カテゴリ化前の訓練データの大きさ： 62732\n"
     ]
    }
   ],
   "source": [
    "locations = df['所在地']\n",
    "\n",
    "#以下の部分では訓練データの”区”のラベル化に備えて、〇〇区の部分を抽出する。\n",
    "i = 0\n",
    "merge_addresses = []\n",
    "for loc in locations:\n",
    "    loc = mojimoji.zen_to_han(loc, kana=True)#所在地に含まれる全角数字を半角数字に変換\n",
    "    digits = re.findall(r\"\\d+\", loc)#n丁目などの数字情報を取得する\n",
    "    target1 = \"都\"\n",
    "    idx1 = loc.find(target1)\n",
    "    try:\n",
    "        idx2 = loc.find(digits[0])\n",
    "    except:\n",
    "        idx2 = -1#digitsがnanだったら-1を代入することで後々のスライスに備える\n",
    "    address = loc[idx1+1:idx2]\n",
    "    merge_addresses.append(address)\n",
    "\n",
    "merge_addresses = pd.DataFrame(merge_addresses)\n",
    "merge_addresses = merge_addresses.rename(columns={0:'所在地'})#列名の振り直し\n",
    "print(\"カテゴリ化前の訓練データ：\")\n",
    "print(merge_addresses.head(20))\n",
    "print(\"カテゴリ化前の訓練データの大きさ：\",len(merge_addresses))\n",
    "\n",
    "\n",
    "#カテゴリ化\n",
    "list_cols = ['所在地']\n",
    "addresses_encoder = ce.OrdinalEncoder(cols=list_cols, drop_invariant=True)\n",
    "merge_addresses = addresses_encoder.fit_transform(merge_addresses['所在地'])\n",
    "#訓練データとテストデータに再分割\n",
    "addresses = merge_addresses[:len(df_target)]\n",
    "addresses.to_csv('addresses.csv',index=False)\n",
    "test_addresses = merge_addresses[len(df_target):]\n",
    "test_addresses.to_csv('test_addresses.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の読み込みを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       所在地\n",
      "0      441\n",
      "1      271\n",
      "2      132\n",
      "3      264\n",
      "4      343\n",
      "...    ...\n",
      "31257  119\n",
      "31258  316\n",
      "31259   21\n",
      "31260  845\n",
      "31261  190\n",
      "\n",
      "[31262 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "test_addresses = test_addresses.reset_index(drop=True)\n",
    "print(test_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_age = pd.read_csv('house_age.csv')\n",
    "area_size = pd.read_csv('area_size.csv')\n",
    "room_arrange_scores = pd.read_csv('room_arrange_scores.csv')\n",
    "contract_span = pd.read_csv('contract_span.csv')\n",
    "floor_scores = pd.read_csv('floor_scores.csv')\n",
    "Floor_scores = pd.read_csv('capital_floor_scores.csv')\n",
    "wards = pd.read_csv('wards.csv')\n",
    "stations = pd.read_csv('stations.csv')\n",
    "minits = pd.read_csv('minits.csv')\n",
    "\n",
    "rent = pd.read_csv('rent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_house_age = pd.read_csv('test_house_age.csv')\n",
    "test_area_size = pd.read_csv('test_area_size.csv')\n",
    "test_room_arrange_scores = pd.read_csv('test_room_arrange_scores.csv')\n",
    "test_contract_span = pd.read_csv('test_contract_span.csv')\n",
    "test_floor_scores = pd.read_csv('test_floor_scores.csv')\n",
    "test_Floor_scores = pd.read_csv('test_capital_floor_scores.csv')\n",
    "test_wards = pd.read_csv('test_wards.csv')\n",
    "test_stations = pd.read_csv('test_stations.csv')\n",
    "test_minits = pd.read_csv('test_minits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをlightGBMに突っ込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1868\n",
      "[LightGBM] [Info] Number of data points in the train set: 22029, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118651.337373\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 37615.7\tvalid_1's rmse: 42777.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['所在地', '最寄り駅']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's rmse: 23279.9\tvalid_1's rmse: 31714.1\n",
      "[30]\ttraining's rmse: 17917.4\tvalid_1's rmse: 27630.5\n",
      "[40]\ttraining's rmse: 15470.1\tvalid_1's rmse: 25857\n",
      "[50]\ttraining's rmse: 14177.4\tvalid_1's rmse: 25019.9\n",
      "[60]\ttraining's rmse: 13348.8\tvalid_1's rmse: 24539.6\n",
      "[70]\ttraining's rmse: 12692.2\tvalid_1's rmse: 24212.8\n",
      "[80]\ttraining's rmse: 12171.4\tvalid_1's rmse: 23883.8\n",
      "[90]\ttraining's rmse: 11643.6\tvalid_1's rmse: 23608.5\n",
      "[100]\ttraining's rmse: 11166.3\tvalid_1's rmse: 23327.5\n",
      "[110]\ttraining's rmse: 10828.1\tvalid_1's rmse: 23149.4\n",
      "[120]\ttraining's rmse: 10534.7\tvalid_1's rmse: 23045.5\n",
      "[130]\ttraining's rmse: 10246.6\tvalid_1's rmse: 22926.6\n",
      "[140]\ttraining's rmse: 9980.65\tvalid_1's rmse: 22793.8\n",
      "[150]\ttraining's rmse: 9731.38\tvalid_1's rmse: 22665\n",
      "[160]\ttraining's rmse: 9539.54\tvalid_1's rmse: 22614\n",
      "[170]\ttraining's rmse: 9361.29\tvalid_1's rmse: 22545.4\n",
      "[180]\ttraining's rmse: 9176.06\tvalid_1's rmse: 22493.5\n",
      "[190]\ttraining's rmse: 8988.08\tvalid_1's rmse: 22421.3\n",
      "[200]\ttraining's rmse: 8820\tvalid_1's rmse: 22348.3\n",
      "[210]\ttraining's rmse: 8671.29\tvalid_1's rmse: 22304.1\n",
      "[220]\ttraining's rmse: 8542.54\tvalid_1's rmse: 22263.6\n",
      "[230]\ttraining's rmse: 8412.62\tvalid_1's rmse: 22216.6\n",
      "[240]\ttraining's rmse: 8300.32\tvalid_1's rmse: 22175\n",
      "[250]\ttraining's rmse: 8190.39\tvalid_1's rmse: 22146\n",
      "[260]\ttraining's rmse: 8065.58\tvalid_1's rmse: 22129.6\n",
      "[270]\ttraining's rmse: 7954.33\tvalid_1's rmse: 22108.1\n",
      "[280]\ttraining's rmse: 7841.64\tvalid_1's rmse: 22083.8\n",
      "[290]\ttraining's rmse: 7746.19\tvalid_1's rmse: 22065.1\n",
      "[300]\ttraining's rmse: 7641.78\tvalid_1's rmse: 22034.6\n",
      "[310]\ttraining's rmse: 7569.29\tvalid_1's rmse: 22014\n",
      "[320]\ttraining's rmse: 7497.15\tvalid_1's rmse: 22002.5\n",
      "[330]\ttraining's rmse: 7421.19\tvalid_1's rmse: 21982.6\n",
      "[340]\ttraining's rmse: 7341.34\tvalid_1's rmse: 21967.2\n",
      "[350]\ttraining's rmse: 7255.82\tvalid_1's rmse: 21952.7\n",
      "[360]\ttraining's rmse: 7171.74\tvalid_1's rmse: 21938.5\n",
      "[370]\ttraining's rmse: 7110.07\tvalid_1's rmse: 21927.6\n",
      "[380]\ttraining's rmse: 7044.51\tvalid_1's rmse: 21909\n",
      "[390]\ttraining's rmse: 6979.31\tvalid_1's rmse: 21899.6\n",
      "[400]\ttraining's rmse: 6919.42\tvalid_1's rmse: 21883.7\n",
      "[410]\ttraining's rmse: 6855.6\tvalid_1's rmse: 21871.2\n",
      "[420]\ttraining's rmse: 6788.44\tvalid_1's rmse: 21857.2\n",
      "[430]\ttraining's rmse: 6724.06\tvalid_1's rmse: 21858.7\n",
      "[440]\ttraining's rmse: 6664.1\tvalid_1's rmse: 21851.2\n",
      "[450]\ttraining's rmse: 6607.13\tvalid_1's rmse: 21839.7\n",
      "[460]\ttraining's rmse: 6563.13\tvalid_1's rmse: 21835.7\n",
      "[470]\ttraining's rmse: 6509.66\tvalid_1's rmse: 21816.6\n",
      "[480]\ttraining's rmse: 6469.09\tvalid_1's rmse: 21803\n",
      "[490]\ttraining's rmse: 6419\tvalid_1's rmse: 21796.7\n",
      "[500]\ttraining's rmse: 6375.77\tvalid_1's rmse: 21786\n",
      "[510]\ttraining's rmse: 6338.38\tvalid_1's rmse: 21782.3\n",
      "[520]\ttraining's rmse: 6290.7\tvalid_1's rmse: 21773.3\n",
      "[530]\ttraining's rmse: 6244.87\tvalid_1's rmse: 21765\n",
      "[540]\ttraining's rmse: 6201.2\tvalid_1's rmse: 21766.2\n",
      "[550]\ttraining's rmse: 6158.78\tvalid_1's rmse: 21757.5\n",
      "[560]\ttraining's rmse: 6122.36\tvalid_1's rmse: 21749.2\n",
      "[570]\ttraining's rmse: 6076.72\tvalid_1's rmse: 21740.9\n",
      "[580]\ttraining's rmse: 6028.42\tvalid_1's rmse: 21733\n",
      "[590]\ttraining's rmse: 5981.74\tvalid_1's rmse: 21722.1\n",
      "[600]\ttraining's rmse: 5939.42\tvalid_1's rmse: 21720.6\n",
      "[610]\ttraining's rmse: 5901.31\tvalid_1's rmse: 21713.4\n",
      "[620]\ttraining's rmse: 5871.16\tvalid_1's rmse: 21701.6\n",
      "[630]\ttraining's rmse: 5837.85\tvalid_1's rmse: 21694.5\n",
      "[640]\ttraining's rmse: 5809.78\tvalid_1's rmse: 21690.2\n",
      "[650]\ttraining's rmse: 5767.94\tvalid_1's rmse: 21684.8\n",
      "[660]\ttraining's rmse: 5736.84\tvalid_1's rmse: 21679.6\n",
      "[670]\ttraining's rmse: 5712.31\tvalid_1's rmse: 21677.6\n",
      "[680]\ttraining's rmse: 5673.26\tvalid_1's rmse: 21670.5\n",
      "[690]\ttraining's rmse: 5639.4\tvalid_1's rmse: 21666.6\n",
      "[700]\ttraining's rmse: 5605.62\tvalid_1's rmse: 21658.5\n",
      "[710]\ttraining's rmse: 5577.36\tvalid_1's rmse: 21655.2\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's rmse: 5590.24\tvalid_1's rmse: 21653.7\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([house_age, area_size, room_arrange_scores, contract_span, floor_scores, Floor_scores, stations, minits, addresses], axis=1)\n",
    "y_train = rent\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "X_test = pd.concat([test_house_age, test_area_size, test_room_arrange_scores, test_contract_span, test_floor_scores, test_Floor_scores, test_stations, test_minits, test_addresses['所在地']], axis=1)\n",
    "\n",
    "category_lists = ['最寄り駅', '所在地']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective':'regression',\n",
    "    'metrics':'rmse',\n",
    "    'lambda_l2':0.0000001\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "                    params,\n",
    "                    lgb_train, \n",
    "                    valid_sets=[lgb_train, lgb_eval], \n",
    "                    verbose_eval=10, \n",
    "                    num_boost_round=3000, \n",
    "                    early_stopping_rounds=10,\n",
    "                    categorical_feature = category_lists\n",
    "                    )\n",
    "\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "id = df['id']\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "result = pd.concat([id, y_pred],axis=1)\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['id'] = result['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b37a52d913339e4f7edd98eba251795ba561325231c15b6137ab41e2758152be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
