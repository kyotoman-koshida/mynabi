{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6hoaEQdm5RG",
        "outputId": "cbc10ef8-667b-4cdc-dc20-cb20c6493d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow-gpu\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLGfaAuhKlz"
      },
      "source": [
        "トレーニングデータの説明変数とテストデータをロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hf2hlSgnrLY"
      },
      "outputs": [],
      "source": [
        "lgbm_path = '/content/drive/MyDrive/apartment_price_forecasting/data/stacking/20220916/lgbm/'\n",
        "goss_path = '/content/drive/MyDrive/apartment_price_forecasting/data/stacking/20220916/goss/'\n",
        "\n",
        "with open(lgbm_path + 'preds_train_lgbm.pkl', 'rb') as f:\n",
        "    preds_train_lgbm = pickle.load(f)\n",
        "\n",
        "with open(lgbm_path + 'preds_test_lgbm.pkl', 'rb') as f:\n",
        "    preds_test_lgbm = pickle.load(f)\n",
        "\n",
        "with open(goss_path + 'preds_train_goss.pkl', 'rb') as f:\n",
        "    preds_train_goss = pickle.load(f)\n",
        "\n",
        "with open(goss_path + 'preds_test_goss.pkl', 'rb') as f:\n",
        "    preds_test_goss = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K-7C-1XgpsE"
      },
      "outputs": [],
      "source": [
        "train_x = np.concatenate((preds_train_lgbm, preds_train_goss), axis=0).transpose()\n",
        "test_x = np.concatenate((preds_test_lgbm, preds_test_goss), axis=0).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFXYuxDVhNXr"
      },
      "source": [
        "トレーニングデータの目的変数をロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Z5HBPKhBVU"
      },
      "outputs": [],
      "source": [
        "pickle_path = '/content/drive/MyDrive/apartment_price_forecasting/data/training_data/df_concat_ch:layout_cnst_usage_no_ext.pkl'\n",
        "with open(pickle_path, 'rb') as f:\n",
        "    df_concat = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrCSDi7_Ewfh"
      },
      "outputs": [],
      "source": [
        "rm_col = ['parking', 'shop', 'others', 'plant', 'warehouse', 'workshop', 'house', 'office', 'usage_unknown', 'usage_le', 'construction_structure_le', 'layout_le']\n",
        "df_concat = df_concat.drop(rm_col, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22V0DLXtQw9R"
      },
      "outputs": [],
      "source": [
        "pickle_path = '/content/drive/MyDrive/apartment_price_forecasting/data/training_data/'\n",
        "with open(pickle_path + 'df_train_ext.pkl', 'rb') as f:\n",
        "    df_train_ext = pickle.load(f)\n",
        "\n",
        "with open(pickle_path + 'df_test_ext.pkl', 'rb') as f:\n",
        "    df_test_ext = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxJYJ05JQywq"
      },
      "outputs": [],
      "source": [
        "df_train_ext = df_train_ext[['ID', 'passengers_2017', 'lon', 'lat', 'r2_price']]\n",
        "df_test_ext = df_test_ext[['ID', 'passengers_2017', 'lon', 'lat', 'r2_price']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKU1dGXTQ86f"
      },
      "outputs": [],
      "source": [
        "df_train = pd.merge(df_concat.query('y >= 0'), df_train_ext, on='ID', how='left')\n",
        "df_test = pd.merge(df_concat.query('not y >= 0'), df_test_ext, on='ID', how='left').drop('y', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03zO4jfZQ_sT"
      },
      "outputs": [],
      "source": [
        "train_y = np.array(df_train['y']).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iUtt-1m7raQ"
      },
      "source": [
        "###スタッキング第二層：線形回帰モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o11ZbdTsIzyH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMenHZKII3PX"
      },
      "source": [
        "シンプルな線形回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCMYhvHXhxRg"
      },
      "outputs": [],
      "source": [
        "idx = int(train_x.shape[0] * 0.7)\n",
        "x_train = train_x[:idx, :]\n",
        "x_valid = train_x[idx:, :]\n",
        "y_train = train_y[:idx, :]\n",
        "y_valid = train_y[idx:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngsmTJZe9L8W"
      },
      "outputs": [],
      "source": [
        "# メタモデルの学習 \n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(x_train, y_train)\n",
        "valid_pred = meta_model.predict(x_valid)\n",
        "mae_avg = np.abs(valid_pred - y_valid).sum(axis=0) / valid_pred.shape[0]\n",
        "print(mae_avg)\n",
        "pred_test = meta_model.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kqp7jZ-I8Oa"
      },
      "source": [
        "k-foldで分割して線形回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9uN9_Jb7qla"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for train_index, valid_index in kf.split(train_x):\n",
        "    x_train = train_x[train_index, :]\n",
        "    y_train = train_y[train_index, :]\n",
        "\n",
        "    # メタモデルの学習 \n",
        "    meta_model = LinearRegression()\n",
        "    meta_model.fit(x_train, y_train)\n",
        "    pred_list.append(meta_model.predict(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ymeHS8B9WbX"
      },
      "outputs": [],
      "source": [
        "pred_test =np.array(pred_list).mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2PXmgKP_C8m"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/apartment_price_forecasting/data/sample_submission.csv'\n",
        "sample_sub = pd.read_csv(data_path)\n",
        "sample_sub['取引価格（総額）_log'] = pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVZGHJee_PCE"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/apartment_price_forecasting/data/'\n",
        "sample_sub.to_csv(save_path + 'test_submission_stacking_linear.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbwnvocJ4Vhh"
      },
      "source": [
        "### スタッキング第二層：SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4dpvRpO4UTe",
        "outputId": "1b1ac4ab-3089-44ab-e649-bb5559693182"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for train_index, valid_index in kf.split(train_x):\n",
        "    x_train = train_x[train_index, :]\n",
        "    y_train = train_y[train_index, :]\n",
        "\n",
        "    # メタモデルの学習 \n",
        "    regr = SVR()\n",
        "    regr.fit(x_train, y_train)\n",
        "    pred_list.append(regr.predict(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqKdE4VS40if"
      },
      "outputs": [],
      "source": [
        "pred_test =np.array(pred_list).mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXlWFsmIhcgp"
      },
      "source": [
        "### スタッキング第二層：NNモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgR6z_guhVoA"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(5, activation='relu', input_shape=(train_x.shape[1],))) #activationは活性化関数\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "#モデルを構築\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.005), loss='mae', metrics=['mae'])\n",
        "\n",
        "#EaelyStoppingの設定\n",
        "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVLbz9SXhnzZ",
        "outputId": "7f46761f-2adc-4647-d258-6b5bdc5ce2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------- training No. 1 ---------------------------\n",
            "Epoch 1/3000\n",
            "1084/1084 [==============================] - 3s 2ms/step - loss: 0.0872 - mae: 0.0872 - val_loss: 0.0746 - val_mae: 0.0746\n",
            "Epoch 2/3000\n",
            "1084/1084 [==============================] - 3s 3ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0740 - val_mae: 0.0740\n",
            "Epoch 3/3000\n",
            "1084/1084 [==============================] - 3s 3ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0728 - val_mae: 0.0728\n",
            "Epoch 4/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0725 - val_mae: 0.0725\n",
            "Epoch 5/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.0726 - val_mae: 0.0726\n",
            "Epoch 6/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0732 - val_mae: 0.0732\n",
            "--------------------------- training No. 2 ---------------------------\n",
            "Epoch 1/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0750 - val_mae: 0.0750\n",
            "Epoch 2/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0767 - val_mae: 0.0767\n",
            "Epoch 3/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0736 - val_mae: 0.0736\n",
            "Epoch 4/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.0749 - val_mae: 0.0749\n",
            "Epoch 5/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0727 - val_mae: 0.0727\n",
            "Epoch 6/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0728 - val_mae: 0.0728\n",
            "Epoch 7/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0741 - val_mae: 0.0741\n",
            "--------------------------- training No. 3 ---------------------------\n",
            "Epoch 1/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0729 - val_mae: 0.0729\n",
            "Epoch 2/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.0723 - val_mae: 0.0723\n",
            "Epoch 3/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.0745 - val_mae: 0.0745\n",
            "Epoch 4/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0728 - val_mae: 0.0728\n",
            "--------------------------- training No. 4 ---------------------------\n",
            "Epoch 1/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0746 - val_mae: 0.0746\n",
            "Epoch 2/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.0738 - val_mae: 0.0738\n",
            "Epoch 3/3000\n",
            "1084/1084 [==============================] - 3s 3ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0737 - val_mae: 0.0737\n",
            "Epoch 4/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0736 - mae: 0.0736 - val_loss: 0.0725 - val_mae: 0.0725\n",
            "Epoch 5/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0724 - val_mae: 0.0724\n",
            "Epoch 6/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0734 - mae: 0.0734 - val_loss: 0.0749 - val_mae: 0.0749\n",
            "Epoch 7/3000\n",
            "1084/1084 [==============================] - 2s 2ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0725 - val_mae: 0.0725\n"
          ]
        }
      ],
      "source": [
        "#モデルを学習させる\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
        "\n",
        "pred_list = []\n",
        "log_list = []\n",
        "model_list = []\n",
        "cnt = 1\n",
        "for train_index, valid_index in kf.split(train_x):\n",
        "    print('--------------------------- training No. %d' %cnt + ' ---------------------------')\n",
        "    x_train = train_x[train_index, :]\n",
        "    y_train = train_y[train_index, :]\n",
        "    x_valid = train_x[valid_index, :]\n",
        "    y_valid = train_y[valid_index, :]\n",
        "\n",
        "    # メタモデルの学習 \n",
        "    log = model.fit(x_train, y_train, epochs=3000, batch_size=500, verbose=True, validation_data=(x_valid, y_valid), callbacks=[early_stopping])\n",
        "    pred_list.append(model.predict(test_x))\n",
        "    log_list.append(log)\n",
        "    model_list.append(model)\n",
        "    \n",
        "    cnt += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWBRyN0BYvxm"
      },
      "outputs": [],
      "source": [
        "y = np.array(pred_list).mean(axis=0).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMKRxpxGjFS6"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/apartment_price_forecasting/data/sample_submission.csv'\n",
        "sample_sub = pd.read_csv(data_path)\n",
        "sample_sub['取引価格（総額）_log'] = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PgI-u7vYgcH"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/apartment_price_forecasting/data/'\n",
        "sample_sub.to_csv(save_path + 'test_submission_stacking_NN_20220920.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaT9nGRKVV07"
      },
      "outputs": [],
      "source": [
        "best_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_AKEa7cVcNv"
      },
      "outputs": [],
      "source": [
        "best_list.append(pred_list[1])\n",
        "best_list.append(pred_list[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWTDEsX7bHh0",
        "outputId": "3da9ecf9-9be2-4a9d-856a-b1fce07b8790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21005, 1)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.array(pred_list).mean(axis=0).reshape(-1, 1)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFK-I7G_b7nT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "b37a52d913339e4f7edd98eba251795ba561325231c15b6137ab41e2758152be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
