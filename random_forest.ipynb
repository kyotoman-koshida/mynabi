{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import mojimoji\n",
    "import re\n",
    "from cmath import nan\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBMではなくて、ランダムフォレストを使ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_age = pd.read_csv('house_age.csv')\n",
    "area_size = pd.read_csv('area_size.csv')\n",
    "room_arrange = pd.read_csv('room_arrange.csv')\n",
    "contract_span = pd.read_csv('contract_span.csv')\n",
    "floor_scores = pd.read_csv('floor_scores.csv')\n",
    "Floor_scores = pd.read_csv('capital_floor_scores.csv')\n",
    "addresses = pd.read_csv('addresses.csv')\n",
    "stations = pd.read_csv('stations.csv')\n",
    "minits = pd.read_csv('minits.csv')\n",
    "\n",
    "rent = pd.read_csv('rent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_house_age = pd.read_csv('test_house_age.csv')\n",
    "test_area_size = pd.read_csv('test_area_size.csv')\n",
    "test_room_arrange = pd.read_csv('test_room_arrange.csv')\n",
    "test_contract_span = pd.read_csv('test_contract_span.csv')\n",
    "test_floor_scores = pd.read_csv('test_floor_scores.csv')\n",
    "test_Floor_scores = pd.read_csv('test_capital_floor_scores.csv')\n",
    "test_addresses = pd.read_csv('test_addresses.csv')\n",
    "test_stations = pd.read_csv('test_stations.csv')\n",
    "test_minits = pd.read_csv('test_minits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([house_age, area_size, contract_span, floor_scores, Floor_scores, stations, minits, addresses, room_arrange], axis=1)\n",
    "y_train = rent\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "X_test = pd.concat([test_house_age, test_area_size, test_contract_span, test_floor_scores, test_Floor_scores, test_stations, test_minits, test_addresses, test_room_arrange], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>築年数</th>\n",
       "      <th>面積</th>\n",
       "      <th>契約期間</th>\n",
       "      <th>所在階</th>\n",
       "      <th>全体の階数</th>\n",
       "      <th>最寄り駅</th>\n",
       "      <th>所要時間</th>\n",
       "      <th>所在地</th>\n",
       "      <th>部屋数</th>\n",
       "      <th>L</th>\n",
       "      <th>D</th>\n",
       "      <th>K</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>589.0</td>\n",
       "      <td>28.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15190</th>\n",
       "      <td>29.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>417</td>\n",
       "      <td>8.0</td>\n",
       "      <td>659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28196</th>\n",
       "      <td>365.0</td>\n",
       "      <td>44.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86</td>\n",
       "      <td>13.0</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18762</th>\n",
       "      <td>4.0</td>\n",
       "      <td>33.91</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13923</th>\n",
       "      <td>143.0</td>\n",
       "      <td>22.62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>385</td>\n",
       "      <td>2.0</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>181.0</td>\n",
       "      <td>50.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>141</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>388.0</td>\n",
       "      <td>36.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>374.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>154</td>\n",
       "      <td>13.0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>413.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73</td>\n",
       "      <td>15.0</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22029 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         築年数     面積  契約期間  所在階  全体の階数  最寄り駅  所要時間  所在地  部屋数  L  D  K  S\n",
       "1382   589.0  28.35   3.0  2.0   12.0    99   4.0  514    1  1  1  1  0\n",
       "15190   29.0  25.45   2.0  3.0    3.0   417   8.0  659    1  0  0  1  0\n",
       "28196  365.0  44.55   2.0  7.0   11.0    86  13.0  256    2  0  1  1  0\n",
       "18762    4.0  33.91   2.0  7.0   13.0    16   4.0   16    2  0  0  1  0\n",
       "13923  143.0  22.62   2.0  2.0   10.0   385   2.0  370    1  0  0  1  0\n",
       "...      ...    ...   ...  ...    ...   ...   ...  ...  ... .. .. .. ..\n",
       "13123  181.0  50.01   2.0  1.0    2.0    61   NaN  304    2  0  1  1  0\n",
       "19648    0.0  25.80   2.0  2.0    4.0   141   6.0   14    1  0  0  1  0\n",
       "9845   388.0  36.72   2.0  NaN    NaN    51   NaN  558    1  0  1  1  0\n",
       "10799  374.0  19.00   0.0  1.0    2.0   154  13.0  133    1  0  0  0  0\n",
       "2732   413.0  13.50   2.0  2.0    5.0    73  15.0  269    1  0  0  0  0\n",
       "\n",
       "[22029 rows x 13 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムフォレストは欠損値を許してくれないので整形をする。これくらいの数の欠損値であれば削除してもよさそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "築年数        3\n",
       "面積         0\n",
       "契約期間      74\n",
       "所在階      481\n",
       "全体の階数    481\n",
       "最寄り駅       0\n",
       "所要時間     177\n",
       "所在地        0\n",
       "部屋数        0\n",
       "L          0\n",
       "D          0\n",
       "K          0\n",
       "S          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データについて\n",
    "Train_Data = pd.concat([X_train, y_train],axis=1)\n",
    "Train_Data = Train_Data.dropna()\n",
    "X_train = Train_Data[['築年数','面積','契約期間','所在階','全体の階数','最寄り駅','所要時間','所在地','部屋数','L','D','K','S']]\n",
    "y_train = Train_Data[['賃料']]\n",
    "\n",
    "#検証データについて\n",
    "Valid_Data = pd.concat([X_valid, y_valid],axis=1)\n",
    "Valid_Data = Valid_Data.dropna()\n",
    "X_valid = Valid_Data[['築年数','面積','契約期間','所在階','全体の階数','最寄り駅','所要時間','所在地','部屋数','L','D','K','S']]\n",
    "y_valid = Valid_Data[['賃料']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/20ftf7rn5_58_rk3l25kt1nr0000gn/T/ipykernel_5212/2176165941.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8594671351795132\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_valid)\n",
    "print(r2_score(y_valid,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このランダムフォレストをハイパーパラメータチューニングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データについて\n",
    "X_train = pd.concat([house_age, area_size, contract_span, floor_scores, Floor_scores, stations, minits, addresses, room_arrange], axis=1)\n",
    "y_train = rent\n",
    "Train_Data = pd.concat([X_train, y_train],axis=1)\n",
    "Train_Data = Train_Data.dropna()\n",
    "X_train = Train_Data[['築年数','面積','契約期間','所在階','全体の階数','最寄り駅','所要時間','所在地','部屋数','L','D','K','S']]\n",
    "y_train = Train_Data[['賃料']]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "#検証データについて\n",
    "X_test = pd.concat([test_house_age, test_area_size, test_contract_span, test_floor_scores, test_Floor_scores, test_stations, test_minits, test_addresses, test_room_arrange], axis=1)\n",
    "Valid_Data = pd.concat([X_valid, y_valid],axis=1)\n",
    "Valid_Data = Valid_Data.dropna()\n",
    "X_valid = Valid_Data[['築年数','面積','契約期間','所在階','全体の階数','最寄り駅','所要時間','所在地','部屋数','L','D','K','S']]\n",
    "y_valid = Valid_Data[['賃料']]\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 5, 300),\n",
    "        #'max_features'      : [i for i in range(1,train_data_bs.shape[1])],\n",
    "        'random_state': 0,\n",
    "        'n_jobs': 1,\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 100),\n",
    "    }\n",
    "\n",
    "    clf = RandomForestRegressor(\n",
    "                                **params,#ここでアスタリスク２つをつけないとエラーになる。\n",
    "                                )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    loss = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/20ftf7rn5_58_rk3l25kt1nr0000gn/T/ipykernel_5212/4243251184.py:33: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "Trial 0 failed because of the following error: ValueError('Input X contains NaN.\\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/qh/20ftf7rn5_58_rk3l25kt1nr0000gn/T/ipykernel_5212/4243251184.py\", line 35, in objective\n",
      "    y_pred = clf.predict(X_test)\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 991, in predict\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 605, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/base.py\", line 577, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Users/koshidatatsuo/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル13 を /Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=0'>1</a>\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mdisable_default_handler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=1'>2</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(sampler\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mRandomSampler(seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=2'>3</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=3'>4</a>\u001b[0m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mセル13 を /Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=28'>29</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=29'>30</a>\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\u001b[39m#ここでアスタリスク２つをつけないとエラーになる。\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=30'>31</a>\u001b[0m                             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=32'>33</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=34'>35</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=36'>37</a>\u001b[0m loss \u001b[39m=\u001b[39m mean_squared_error(y_valid, y_pred, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/koshidatatsuo/python/signate/mynabi/mynabi/random_forest.ipynb#ch0000019?line=37'>38</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:991\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    989\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    990\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    993\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    994\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 605\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/python/signate/mynabi/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "optuna.logging.disable_default_handler()\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n",
    "study.optimize(objective, n_trials=50)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b37a52d913339e4f7edd98eba251795ba561325231c15b6137ab41e2758152be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
