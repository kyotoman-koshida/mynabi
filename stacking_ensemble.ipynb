{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stackingのアンサンブル用シート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "# import mojimoji\n",
    "import re\n",
    "from cmath import nan\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###訓練データの読み込み\n",
    "house_age = pd.read_csv('house_age.csv')\n",
    "area_size = pd.read_csv('area_size.csv')\n",
    "room_arrange = pd.read_csv('room_arrange.csv')\n",
    "contract_span = pd.read_csv('contract_span.csv')#欠損値をゼロ埋めした契約期間\n",
    "contract_span2 = pd.read_csv('contract_span2.csv')#欠損値を欠損値のままにした契約期間\n",
    "reg_rent = pd.read_csv('reg_rent.csv')\n",
    "floor_scores = pd.read_csv('floor_scores.csv')#「所在階」と「全体の階数」が連動して欠損値になる場合のある「所在階」\n",
    "floor_scores2 = pd.read_csv('floor_scores2.csv')#「所在階」と「全体の階数」が独立している「所在階」\n",
    "Floor_scores = pd.read_csv('capital_floor_scores.csv')#「所在階」と「全体の階数」が連動して欠損値になる場合のある「全体の階数」\n",
    "Floor_scores2 = pd.read_csv('capital_floor_scores2.csv')#「所在階」と「全体の階数」が独立している「全体の階数」\n",
    "stations = pd.read_csv('stations.csv')\n",
    "minits = pd.read_csv('minits.csv')\n",
    "addresses = pd.read_csv('addresses.csv')\n",
    "room_arrange = pd.read_csv('room_arrange.csv')\n",
    "buildings = pd.read_csv('buildings.csv')\n",
    "\n",
    "rent = pd.read_csv('rent.csv')\n",
    "\n",
    "\n",
    "##テストデータの読み込み\n",
    "test_house_age = pd.read_csv('test_house_age.csv')\n",
    "test_area_size = pd.read_csv('test_area_size.csv')\n",
    "test_room_arrange = pd.read_csv('test_room_arrange.csv')\n",
    "test_contract_span = pd.read_csv('test_contract_span.csv')\n",
    "test_contract_span2 = pd.read_csv('test_contract_span2.csv')\n",
    "test_reg_rent = pd.read_csv('test_reg_rent.csv')\n",
    "test_floor_scores = pd.read_csv('test_floor_scores.csv')\n",
    "test_floor_scores2 = pd.read_csv('test_floor_scores2.csv')\n",
    "test_Floor_scores = pd.read_csv('test_capital_floor_scores.csv')\n",
    "test_Floor_scores2 = pd.read_csv('test_capital_floor_scores2.csv')\n",
    "test_stations = pd.read_csv('test_stations.csv')\n",
    "test_minits = pd.read_csv('test_minits.csv')\n",
    "test_addresses = pd.read_csv('test_addresses.csv')\n",
    "test_room_arrange = pd.read_csv('test_room_arrange.csv')\n",
    "test_buildings = pd.read_csv('test_buildings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBMとDARTとGOSSでstackingのアンサンブルを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([house_age, area_size, contract_span, reg_rent, floor_scores2, Floor_scores2, stations, minits, addresses, room_arrange[[\"部屋数\",\"L\",\"D\",\"K\",\"S\"]]], axis=1)\n",
    "y_train = rent\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "X_test = pd.concat([test_house_age, test_area_size, test_contract_span, test_reg_rent, test_floor_scores2, test_Floor_scores2, test_stations, test_minits, test_addresses, test_room_arrange[[\"部屋数\",\"L\",\"D\",\"K\",\"S\"]]], axis=1)\n",
    "\n",
    "category_lists = ['定期借家','最寄り駅', '所在地', 'L', 'D','K','S']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective':'regression',\n",
    "    'metrics':'rmse',\n",
    "    'reg_lambda': 4.430375245218262e-06,\n",
    "    'max_bin': 502,\n",
    "    'num_leaves': 97\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "                    params\n",
    "                    )\n",
    "# model = lgb.train(\n",
    "#                     params,\n",
    "#                     lgb_train, \n",
    "#                     valid_sets=[lgb_train, lgb_eval], \n",
    "#                     verbose_eval=10, \n",
    "#                     num_boost_round=3000, \n",
    "#                     early_stopping_rounds=10,\n",
    "#                     categorical_feature = category_lists\n",
    "#                     )\n",
    "\n",
    "# y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# # feature importanceを表示\n",
    "# importance = pd.DataFrame(model.feature_importance(importance_type = \"gain\"), index=X_train.columns, columns=['importance'])\n",
    "# display(importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([house_age, area_size, contract_span, reg_rent, floor_scores2, Floor_scores2, stations, minits, addresses, room_arrange[[\"部屋数\",\"L\",\"D\",\"K\",\"S\"]]], axis=1)\n",
    "y_train = rent\n",
    "X_test = pd.concat([test_house_age, test_area_size, test_contract_span2, test_reg_rent, test_floor_scores2, test_Floor_scores2, test_stations, test_minits, test_addresses, test_room_arrange[[\"部屋数\",\"L\",\"D\",\"K\",\"S\"]]], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unknown type of parameter:boosting_type, got:dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mセル12 を c:\\Users\\koshi\\python\\signate\\mynabi\\stacking_ensemble.ipynb\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m model_3 \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mLGBMRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m                     params_3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m                     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# モデルの学習\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m model_1\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m model_2\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/koshi/python/signate/mynabi/stacking_ensemble.ipynb#X15sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m model_3\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, init_score\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m'\u001b[39m, feature_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, categorical_feature\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, init_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[0;32m    896\u001b[0m                 eval_set\u001b[39m=\u001b[39;49meval_set, eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    897\u001b[0m                 eval_init_score\u001b[39m=\u001b[39;49meval_init_score, eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[0;32m    898\u001b[0m                 early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    899\u001b[0m                 categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature, callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    900\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\basic.py:1517\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1514\u001b[0m                 params\u001b[39m.\u001b[39mpop(cat_alias, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1515\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39mcategorical_column\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(categorical_indices)\n\u001b[1;32m-> 1517\u001b[0m params_str \u001b[39m=\u001b[39m param_dict_to_str(params)\n\u001b[0;32m   1518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m params\n\u001b[0;32m   1519\u001b[0m \u001b[39m# process for reference dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\koshi\\python\\signate\\mynabi\\venv\\lib\\site-packages\\lightgbm\\basic.py:294\u001b[0m, in \u001b[0;36mparam_dict_to_str\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    292\u001b[0m         pairs\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mval\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[39melif\u001b[39;00m val \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 294\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown type of parameter:\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m, got:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(val)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(pairs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Unknown type of parameter:boosting_type, got:dict"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #重回帰分析\n",
    "\n",
    "category_lists = ['定期借家','最寄り駅', '所在地', 'L', 'D','K','S']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params_1 = {\n",
    "    'objective':'regression',\n",
    "    'metrics':'rmse',\n",
    "    'reg_lambda': 4.430375245218262e-06,\n",
    "    'max_bin': 502,\n",
    "    'num_leaves': 97\n",
    "}\n",
    "\n",
    "# モデルのインスタンス\n",
    "model_1 = lgb.LGBMRegressor(\n",
    "                    params_1\n",
    "                    )\n",
    "# model_1 = lgb.train(\n",
    "#                     params,\n",
    "#                     lgb_train, \n",
    "#                     valid_sets=[lgb_train, lgb_eval], \n",
    "#                     verbose_eval=10, \n",
    "#                     num_boost_round=1000, \n",
    "#                     early_stopping_rounds=10,\n",
    "#                     categorical_feature = category_lists\n",
    "#                     )\n",
    "\n",
    "# モデルのインスタンス\n",
    "category_lists = ['定期借家','最寄り駅', '所在地', 'L', 'D', 'K','S']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params_2 = {\n",
    "    'objective':'regression',\n",
    "    'boosting_type':'dart',\n",
    "    'metrics':'rmse',\n",
    "    'reg_lambda': 2.1600820741402023e-05,\n",
    "    'max_bin': 556,\n",
    "    'num_leaves': 126\n",
    "}\n",
    "\n",
    "model_2 = lgb.LGBMRegressor(\n",
    "                    params_2\n",
    "                    )\n",
    "# model_2 = lgb.train(\n",
    "#                     params,\n",
    "#                     lgb_train, \n",
    "#                     valid_sets=[lgb_train, lgb_eval], \n",
    "#                     verbose_eval=10, \n",
    "#                     num_boost_round=1000, \n",
    "#                     early_stopping_rounds=10,\n",
    "#                     categorical_feature = category_lists\n",
    "#                     )\n",
    "\n",
    "# モデルのインスタンス\n",
    "category_lists = ['定期借家', '最寄り駅', '所在地', 'L', 'D', 'K','S']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params_3 = {\n",
    "    'objective':'regression',\n",
    "    'boosting_type':'goss',\n",
    "    'metrics':'rmse',\n",
    "    'reg_lambda': 1.2667345328336822e-06,\n",
    "    'max_bin': 405,\n",
    "    'num_leaves': 118\n",
    "}\n",
    "# params = {\n",
    "#     'objective':'regression',\n",
    "#     'boosting_type':'goss',\n",
    "#     'metrics':'rmse',\n",
    "#     'reg_lambda': 1.2667345328336822e-06,\n",
    "#     'max_bin': 405,\n",
    "#     'num_leaves': 118\n",
    "# }\n",
    "\n",
    "model_3 = lgb.LGBMRegressor(\n",
    "                    params_3\n",
    "                    )\n",
    "\n",
    "# モデルの学習\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# 予測値の作成\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一段階の予測値\n",
    "first_pred_1 = model_1.predict(X_valid)\n",
    "first_pred_2 = model_2.predict(X_valid)\n",
    "first_pred_3 = model_3.predict(X_valid)\n",
    "\n",
    "# 第一段階の予測値をまとめる（メタモデルの特徴量）\n",
    "stack_pred = np.column_stack((first_pred_1,first_pred_2,first_pred_3))\n",
    "\n",
    "# メタモデルの作成\n",
    "meta_model = LinearRegression()\n",
    "# 第一段階の予測値の答え = y_valid\n",
    "meta_model.fit(stack_pred, y_valid)\n",
    "\n",
    "# 事前に予測しておいた値でスタッキングの精度を確認する\n",
    "stack_test_pred = np.column_stack((pred_1, pred_2, pred_3))\n",
    "meta_test_pred = meta_model.predict(stack_test_pred)\n",
    "#print (\"メタモデルの平均2乗誤差: {:.4f}\".format(mean_squared_error(y_test, meta_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a98cf4a852aef637b580117f8642dec837d1a50d3f811fd67a8b5a8fce3bf795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
